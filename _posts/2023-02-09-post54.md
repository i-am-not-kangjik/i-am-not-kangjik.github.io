---
title: 2023-02-09 TIL
date: 2023-02-09 17:28:00 +0900
categories: [TIL, playdata]
tags: [ml, scikit-learn, cross validation, logistic regression]     # TAG names should always be lowercase
---
### 편향, 분산 트레이드 오프

- 일반화 오차 = 분산 + 편향^2 + 노이즈
- 편향(Bias)
    - 일반화 오차 중 잘못된 가정으로 인해 생긴 오차
    - 데이터 또는 학습 모델이 정답으로부터 얼마나 특정 방향으로 치우쳐있는가를 의미
    - 학습 모델의 예측값이 정답과 멀리 치우친 경향이 있을 때 고편향되어있다고 한다.
- 분산(Variandce)
    - 훈련 데이터셋에 내재된 작은 변동에 의해 발생하는 오차
    - 데이터 또는 학습 모델이 얼마나 넓은 범위에 걸쳐 분포되어 있는가를 의미
    - 높은 분산값은 학습 모델에서 예측값이 넓게 흩어져 있어 변동성이 높은 때를 말하며 과대 적합되는 경향이 있다.
- 편향-분산 트레이드오프
    - 지도학습 알고리즘이 훈련 데이터셋의 범위를 넘어 지나치게 일반화하는 것을 예방하기 위해
    두 종류의 오차를 최소화할 때 겪는 문제
    - 이상적인 모델 복잡도는 과적합되지 않으며 특정 설명력이 충분한 것
- 편향과 분산의 관계
    - 모델을 학습시킬수록 모델 복잡도는 올라감
    - 학습을 시킬수록 편향은 줄어드나 분산은 올라감
    - 학습이 적을수록 편향을 올라가고 분산은 내려간다
    - 과대적합 : 분산이 높고 편향이 낮아짐
    - 과소적합: 편향이 높고 분산이 낮아짐
    - 전체 오차는 편향-분산 트레이드 오프로 인해 계속 학습시킨다고 줄어드는 것이 아니다.
    - 학습을 통해서 전체 오류가 최소화 되는 지점을 찾으면 그 시점에서의 추정된 모델이 가장 최적의 모델이 된다.

### 교차 검증

- 교차 검증(Cross Validation)
    - 머신러닝 모델을 설계할 때 데이터를 가능한 한 적게 나누기 위한 기법
    - 데이터를 몇 개의 조각으로 나누고 각각의 조각을 검증데이터로 사용하여 모델을 검증하는 방법
    - 각각의 조각 데이터를 하나씩 검증데이터로 사용하면 데이터 세트가 너무 작아 모델의 일반화가 어려워질 수 있으므로 데이터를 몇 개의 조각으로 나누어 여러 번 모델을 검증하는 방법이 교차 검증이다.

### K-폴드 교차 검증

- K-폴드 교차 검증(K-Fold Cross Validation)
    - 교차 검증의 한 종류로, 데이터를 K개의 동일한 크기의 부분 집합(Fold)로 나누고 각각의 폴드를 한 번씩 검증용 데이터로 사용하는 방법
    - 폴드 수를 늘리면 각 모델 검증에 들어가는 데이터량이 줄어들고 일반화된 모델의 정확도가 떨어지기 때문에 K 값을 적당히 선정해야한다.
    - K 값이 커지면 각 모델 검증에 들어가는 데이터량이 늘어나고 일반화된 모델의 정확도는 늘지만 과적합의 위험이 있기 때문에 K 값을 적당히 선정해야한다.
    - K-폴드 교차 검증의 경우 폴드 수를 적절하게 선택하는 것이 매우 중요합니다. 폴드 수가 적을 경우 모델 검증 데이터량이 줄어들고 일반화된 모델 정확도가 떨어지기 때문에 K 값을 적당히 선택해야 합니다. 반면, K 값을 많이 선택할 경우 과적합의 위험이 있기 때문에 적절한 K 값을 선택해야 합니다.
    

## 규제가 있는 선형 회귀

- sklearn.linear_model import LassoCV
    - LassoCV(alphas=alpha_list, cv=cv, max_iter=max_iter, n_jobs=-1, random_state=42)
        - n_jobs 는 cpu에서 사용할 코어 갯수, -1로 주면 알아서 최대로
    - fit한 다음에
        - .alpha_로 최고의 알파값 찾을 수 있다.
        - 알아서 해당 모델에 최적의 값으로 훈련한 값이 들어와 있다.
        
- LassoCV(Lasso 규제가 있는 선형 회귀):
    - LassoCV는 Lasso 규제가 있는 선형 회귀 모델의 최적의 변수를 찾기 위한 알고리즘이다.
    - sklearn에서 제공하는 알고리즘으로 과대적합을 방지하기 위해 alpha 값을 조정하여 가장 최적의 변수를 찾는다.
    - LassoCV는 교차 검증을 사용하여 alpha를 튜닝하고 다양한 alpha값들 중 가장 적절한 alpha 값을 찾는다.
    - 또한 사용하는 CPU의 코어 수를 지정할 수 있으며, 이를 통해 학습 속도를 개선할 수 있다.
    - fit 후에는 .alpha_를 통해 최고의 alpha 값을 찾을 수 있으며, 해당 모델에 최적의 값으로 훈련한 값이 들어있다.

## 로지스틱 회귀

- 시그모이드 함수
- 이진 분류 기능 수행
    - 이름 자체에 회귀라는 단어가 들어가 있지만 분류를 수행함

### 오차 행렬

Tp Tn Fp Fn

Type1 오차 (1형 오차) Fp - 결함이 아닌데, 결함이 있다고 판정

Type2 오차 (2형 오차) Fn - 결함이 있는데, 결합이 없다고 판정


- 다중 클래스들에 대한 분류를 수행하는 회귀 모형을 다항 로지스틱 회귀 또는 소프트맥스 회귀라고 한다.

재현율(recall), 민감도(sensitivity), tpr(true positive rate) 혼용됨