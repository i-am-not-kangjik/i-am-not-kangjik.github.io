---
title: 2023-02-06 TIL
date: 2023-02-06 19:04:00 +0900
categories: [TIL, playdata]
tags: [ml, scikit-learn, iris data, scaler]     # TAG names should always be lowercase
---

## 인공지능의 개요

- 인공지능 : 지적 작업에 필요한 능력(지능)을 사람이 아닌 기계가 가질 수 있도록 하는 것
인간의 지적 능력을 컴퓨터를 통해 구현하는 기술의 총칭
- 머신러닝: 주어진 데이터를 기반으로 학습하여 패턴을 파악하고 이를 이용해 예측하거나 분류를 수행하는 것
- 딥러닝: 머신러닝 알고리즘 중에 인공 신경망 구조를 기반으로 학습하는 방법

## 머신러닝의 의의

- 과거 경험에서 학습을 통해 얻은 지식을 미래의 결정에 이용하는 컴퓨터 과학의 한 분야
- 관측된 패턴을 일반화하거나 주어진 샘플을 통해 새로운 규칙을 생성하는 목표를 가진다.

## 지도학습

- 지도 학습이란 정답(레이블, label)에 근거한 학습 데이터에서 모델을 학습해 데이터를 설명하는 하나의 함수(가설)을 유추하고, 학습하지 않은 미래 데이터에 대해 예측을 만드는 머신러닝의 한 방법
- 유추된 함수 중 연속적인 값을 출력하는 것을 회귀 분석(Regression)이라고 하고,
이산적인 값을 출력하는 것을 분류(Classification)라고 함.
- 이미 정답이 있는 데이터를 컴퓨터에 학습시키는 방법.
- 분류(Classification)
    - 어떤 카테고리(종류) 중 하나를 예측함
    - 강아지인지 고양이인지, 스팸메일 예측, 병명 진단
- 회귀(Regression)
    - 연속적인 값을 예측함
    - 주택의 면적을 고려하여 주택의 가격을 예측
- 지도학습 알고리즘의 종류
    - k-최근접 이웃 (KNN)
    - 선형 회귀
    - 로지스틱 회귀
    - 서포트 벡터 머신(SVM)
    - 결정 트리와 랜덤 포레스트
    - 신경망

## 비지도학습

- 나오는 label의 개수가 정해져있지 않다.
- 정답 데이터를 얻을 수 없는 문제를 학습하는 것
- 알려지지 않은 데이터 구조 탐색
- 비지도 학습 종류
    - 군집화 - 유사한 그룹으로 클러스터링
    - 시각화와 차원 축소 - 하나의 관측 샘플에 있는 많은 특성(고차원)의 수를 줄임(저차원)으로써
    알고리즘의 성능을 개선하거나 시각화에 도움을 줌
    - 연관 규칙 학습
    

# 데이터 베이스 중요!

### 문제 정의 → 데이터 수집 → 데이터 이해 → 데이터 준비 → 모델링 → 모델링 평가

- 데이터 준비
    - 데이터 전처리(라벨 인코딩)
    - 데이터 결합
    - 특성 선택 및 스케일 조정
        - 스케일링? 0~1로
    - 차원 축소, 샘플링
    - 학습데이터와 테스트데이터 분할
- 모델링(학습 알고리즘)
    - 학습모델 정의
    - 모델 학습 및 교차 검증
    - 성능 지표
    - 하이퍼파라미터 최적화
- 모델 평가
    - 테스트(최종) 데이터 예측
    - 고객 솔루션 제시
    

## Scikit-learn 기초

- 예제 데이터
    - sklearn.datasets
- 데이터 전처리
    - sklearn.preprocessing
- 데이터 분리, 검증, 파라미터 튜닝
    - sklearn.model_selection
- 성능 평가
    - sklearn.metrics
- 머신러닝 알고리즘
    - sklearn.linear_model
    - sklearn.svm
    - sklearn.tree
    - sklearn.ensemble
    - sklearn.cluster
- 지원 기능
    - sklearn.pipeline
    
- sklearn의 데이터 표현 방식
    - 특성 행렬(Feature Matrix)
        - 표본(sample): 데이터셋이 설명하는 개별 객체를 나타냄, 행렬의 행
        - 특성(feature): 각 표본을 연속적인 수치, 부울값, 이산값으로 표현하는 개별 관측치를 의미
        - 학습의 결과를 결정하는 데 영향을 미치는 입력 데이터
        - 행의 개수: n_samples
        - 열의 개수: m_features
        - 관례적으로 특성 행렬은 X에 저장
        - 2차원의 배열 구조를 사용: 주로 2차원 ndarray, datframe, SciPy 희소행렬을 사용
        - 독립변수, 입력변수라고도 함.
    - 대상 벡터(Target Vector)
        - 연속적인 수치값, 이산 클래스/레이블을 가짐
        - 길이: n_samples
        - 관례적으로 대상 벡터는 y에 저장
        - 1차원 배열 구조를 주로 사용: 1차원 ndarray, series
        - 특성 행렬로부터 예측하고자 하는 값의 벡터
        - 종속변수, 출력변수, 결과변수, 반응변수, 목표변수라고도 함

- 사이킷런 내장 데이터셋 연습 - iris data
    - 데이터 분할 train_test_split
    - accuracy_score(y_test, y_pred)
- 테스트와 검증
    - overfitting
    - 홀드아웃 검증
    - 교차 검증(Cross Validation, CV)

- 라벨 인코딩
    - 카테고리 피처를 코드형 숫자값으로 변경
    - from sklearn.preprocessing import LabelEncoder
    - transform을 해야 인간이 알아볼 수 있는 형태로 나옴

- 스케일링
    - StandardScaler()
        - 평균 0, 분산 1인 가우시안 정규 분포를 가진 값으로 변환
    - MinMaxScaler()
        - 데이터 값을 0과 1 사이의 범위 값으로 변환